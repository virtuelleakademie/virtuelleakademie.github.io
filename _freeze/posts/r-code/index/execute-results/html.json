{
  "hash": "7e2892b3a31f2d3c8864852245f449db",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Mastering Tidy R: Data Visualization with tidyverse and ggplot2\"\ndate: 5 June, 2025\ndate-format: \"DD MMM, YYYY\"\n\nauthor: \n  - name: Andrew Ellis\n    url: https://github.com/awellis\n    affiliation: Virtual Academy, Bern University of Applied Sciences\n    affiliation-url: https://virtuelleakademie.ch\n    orcid: 0000-0002-2788-936X\n\ncategories: [R, ggplot2, tidyverse, data visualization, tutorial]\nformat:\n    html:\n        code-fold: true\n        code-tools: true\n        code-summary: \"Show the code\"\n        toc: true\n---\n\nThis post demonstrates how to use tidy R code principles with the `tidyverse` ecosystem to create compelling data visualizations using `ggplot2`. We'll explore data manipulation techniques and build publication-ready plots step by step.\n\n## The Tidy Data Philosophy\n\nThe tidyverse is built around the concept of **tidy data**, where:\n\n- Each variable forms a column\n- Each observation forms a row  \n- Each value has its own cell\n\nThis structure makes data analysis more intuitive and code more readable.\n\n## Setup and Data Preparation\n\nFirst, we load the necessary libraries and create some example data to demonstrate key concepts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the tidyverse (includes dplyr, ggplot2, tidyr, readr, and more)\nlibrary(tidyverse)\nlibrary(scales)\n\n# Set a custom theme for our plots\ntheme_set(theme_minimal(base_size = 12))\n\n# Create example dataset: Student performance across different subjects and semesters\nset.seed(123)\nstudent_data <- tibble(\n  student_id = rep(1:100, each = 6),\n  semester = rep(c(\"Fall 2023\", \"Spring 2024\", \"Fall 2024\"), times = 200),\n  subject = rep(c(\"Mathematics\", \"Science\"), times = 300),\n  score = round(rnorm(600, mean = 78, sd = 12), 1),\n  study_hours = round(runif(600, min = 5, max = 25), 1),\n  attendance = round(runif(600, min = 75, max = 100), 1)\n) |>\n  # Add some realistic constraints\n  mutate(\n    score = pmax(0, pmin(100, score)),\n    # Students who study more tend to score higher\n    score = score + (study_hours - mean(study_hours)) * 0.8,\n    # Better attendance correlates with better scores\n    score = score + (attendance - mean(attendance)) * 0.3,\n    score = round(pmax(0, pmin(100, score)), 1)\n  )\n\n# Display the structure of our data\nglimpse(student_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 600\nColumns: 6\n$ student_id  <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ semester    <chr> \"Fall 2023\", \"Spring 2024\", \"Fall 2024\", \"Fall 2023\", \"Spr…\n$ subject     <chr> \"Mathematics\", \"Science\", \"Mathematics\", \"Science\", \"Mathe…\n$ score       <dbl> 74.5, 83.9, 94.4, 83.6, 80.2, 100.0, 79.9, 58.0, 77.0, 73.…\n$ study_hours <dbl> 22.2, 22.7, 14.8, 19.4, 14.7, 24.8, 6.3, 8.2, 20.7, 15.8, …\n$ attendance  <dbl> 78.9, 96.1, 80.4, 91.7, 90.4, 76.2, 98.7, 89.6, 96.5, 88.0…\n```\n\n\n:::\n:::\n\n\n## Data Exploration with dplyr\n\nLet's explore our data using tidy data manipulation techniques:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate summary statistics by subject and semester\nsummary_stats <- student_data |>\n  group_by(subject, semester) |>\n  summarise(\n    n_students = n_distinct(student_id),\n    avg_score = mean(score, na.rm = TRUE),\n    median_score = median(score, na.rm = TRUE),\n    sd_score = sd(score, na.rm = TRUE),\n    avg_study_hours = mean(study_hours, na.rm = TRUE),\n    avg_attendance = mean(attendance, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |>\n  arrange(subject, semester)\n\n# Display the summary\nsummary_stats |>\n  knitr::kable(digits = 2, caption = \"Summary Statistics by Subject and Semester\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Summary Statistics by Subject and Semester\n\n|subject     |semester    | n_students| avg_score| median_score| sd_score| avg_study_hours| avg_attendance|\n|:-----------|:-----------|----------:|---------:|------------:|--------:|---------------:|--------------:|\n|Mathematics |Fall 2023   |        100|     78.82|        79.00|    11.08|           14.75|          87.96|\n|Mathematics |Fall 2024   |        100|     79.59|        80.70|    13.19|           15.70|          86.86|\n|Mathematics |Spring 2024 |        100|     78.29|        80.20|    12.32|           14.96|          87.64|\n|Science     |Fall 2023   |        100|     75.90|        76.70|    12.02|           14.28|          87.61|\n|Science     |Fall 2024   |        100|     77.69|        77.95|    13.27|           14.87|          87.17|\n|Science     |Spring 2024 |        100|     77.23|        77.30|    11.29|           15.91|          87.07|\n\n\n:::\n:::\n\n\n## Creating Effective Visualizations\n\n### 1. Distribution of Scores by Subject\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a violin plot with box plots overlay\np1 <- student_data |>\n  ggplot(aes(x = subject, y = score, fill = subject)) +\n  geom_violin(alpha = 0.7, trim = FALSE) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.8) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.3, end = 0.8) +\n  labs(\n    title = \"Distribution of Student Scores by Subject\",\n    subtitle = \"Violin plots show the full distribution shape with box plots for summary statistics\",\n    x = \"Subject\",\n    y = \"Score (%)\",\n    caption = \"Data: Simulated student performance data\"\n  ) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, color = \"grey40\"),\n    panel.grid.minor = element_blank()\n  )\n\nprint(p1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n### 2. Trend Analysis Across Semesters\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate means and confidence intervals for trend analysis\ntrend_data <- student_data |>\n  group_by(subject, semester) |>\n  summarise(\n    mean_score = mean(score),\n    se = sd(score) / sqrt(n()),\n    ci_lower = mean_score - 1.96 * se,\n    ci_upper = mean_score + 1.96 * se,\n    .groups = \"drop\"\n  ) |>\n  mutate(semester = factor(semester, levels = c(\"Fall 2023\", \"Spring 2024\", \"Fall 2024\")))\n\np2 <- trend_data |>\n  ggplot(aes(x = semester, y = mean_score, color = subject, group = subject)) +\n  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper, fill = subject), \n              alpha = 0.2, color = NA) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  scale_color_viridis_d(option = \"plasma\", begin = 0.3, end = 0.8) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.3, end = 0.8) +\n  labs(\n    title = \"Student Performance Trends Across Semesters\",\n    subtitle = \"Mean scores with 95% confidence intervals\",\n    x = \"Semester\",\n    y = \"Average Score (%)\",\n    color = \"Subject\",\n    fill = \"Subject\",\n    caption = \"Shaded areas represent 95% confidence intervals\"\n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, color = \"grey40\"),\n    legend.position = \"bottom\",\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(p2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=1152}\n:::\n:::\n\n\n### 3. Relationship Between Study Time and Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a sophisticated scatter plot with trend lines\np3 <- student_data |>\n  ggplot(aes(x = study_hours, y = score)) +\n  geom_point(aes(color = subject, alpha = attendance), size = 2) +\n  geom_smooth(aes(color = subject), method = \"lm\", se = TRUE, size = 1.2) +\n  scale_color_viridis_d(option = \"plasma\", begin = 0.3, end = 0.8) +\n  scale_alpha_continuous(range = c(0.3, 0.8), name = \"Attendance %\") +\n  labs(\n    title = \"Relationship Between Study Hours and Academic Performance\",\n    subtitle = \"Point transparency indicates attendance rate\",\n    x = \"Weekly Study Hours\",\n    y = \"Score (%)\",\n    color = \"Subject\",\n    caption = \"Linear trend lines with 95% confidence intervals\"\n  ) +\n  facet_wrap(~semester, ncol = 3) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, color = \"grey40\"),\n    legend.position = \"bottom\",\n    panel.grid.minor = element_blank(),\n    strip.text = element_text(size = 12, face = \"bold\")\n  )\n\nprint(p3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n### 4. Advanced: Heat Map of Performance Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create performance bins and calculate percentages\nheatmap_data <- student_data |>\n  mutate(\n    study_bins = cut(study_hours, \n                     breaks = c(0, 10, 15, 20, 25),\n                     labels = c(\"Low (5-10h)\", \"Medium (10-15h)\", \n                               \"High (15-20h)\", \"Very High (20-25h)\"),\n                     include.lowest = TRUE),\n    score_grade = case_when(\n      score >= 90 ~ \"A (90-100)\",\n      score >= 80 ~ \"B (80-89)\",\n      score >= 70 ~ \"C (70-79)\",\n      score >= 60 ~ \"D (60-69)\",\n      TRUE ~ \"F (<60)\"\n    )\n  ) |>\n  count(study_bins, score_grade, subject) |>\n  group_by(study_bins, subject) |>\n  mutate(percentage = n / sum(n) * 100) |>\n  ungroup()\n\np4 <- heatmap_data |>\n  ggplot(aes(x = study_bins, y = score_grade, fill = percentage)) +\n  geom_tile(color = \"white\", size = 0.5) +\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\")), \n            color = \"white\", fontface = \"bold\", size = 3) +\n  scale_fill_viridis_c(option = \"plasma\", name = \"Percentage\\nof Students\") +\n  labs(\n    title = \"Grade Distribution by Study Time Investment\",\n    subtitle = \"Percentage of students achieving each grade level by study hours\",\n    x = \"Weekly Study Hours\",\n    y = \"Grade Level\",\n    caption = \"Higher study hours clearly correlate with better grades\"\n  ) +\n  facet_wrap(~subject) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, color = \"grey40\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank(),\n    strip.text = element_text(size = 12, face = \"bold\")\n  )\n\nprint(p4)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n## Tidy Code Best Practices Demonstrated\n\nThroughout this analysis, we've followed key tidy R principles:\n\n### 1. **Pipe Operator (`|>`)** for Readable Code Flow\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instead of nested functions:\n# plot(summary(filter(data, condition)))\n\n# Use pipes for clarity:\ndata |>\n  filter(condition) |>\n  summary() |>\n  plot()\n```\n:::\n\n\n### 2. **Consistent Grammar of Graphics**\n- Data (`data =`)\n- Aesthetics (`aes()`)\n- Geometries (`geom_*()`)\n- Scales (`scale_*()`)\n- Themes (`theme()`)\n\n### 3. **Meaningful Variable Names and Grouping**\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group operations clearly\nstudent_data |>\n  group_by(subject, semester) |>\n  summarise(avg_score = mean(score)) |>\n  ungroup()\n```\n:::\n\n\n### 4. **Functional Approach with Consistent Styling**\n- Use `snake_case` for variable names\n- Keep line length reasonable\n- Add meaningful labels and captions\n- Use consistent color schemes\n\n## Key Takeaways\n\n1. **Tidy data structure** makes analysis intuitive and code readable\n2. **dplyr verbs** (`filter`, `mutate`, `summarise`, `group_by`) provide powerful data manipulation\n3. **ggplot2's grammar of graphics** enables building complex visualizations systematically\n4. **Consistent styling and theming** makes plots publication-ready\n5. **Pipe operator** creates readable analysis workflows\n\nThe tidyverse ecosystem provides a coherent framework for data science that emphasizes code readability, reproducibility, and elegant solutions to common data challenges.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}